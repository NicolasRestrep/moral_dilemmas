---
title: "Preliminary Analysis - Reaction Time Data"
author: "Nicolas Restrepo"
date: "2/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F)
```

## Preliminary analysis of the full sample

```{r}
# Packages 
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggrepel)
library(gridExtra)
library(haven)
library(lavaan)
library(lme4)
library(nlme)
library(stargazer)
library(broom)
library(psych)
library(brms)
library(plotly)
library(sjPlot)
library(corrplot)
theme_set(theme_light())
```

Let's begin by loading in both datasets. 

```{r}

# Load in conservative data
rt_conservative <- read_csv("rt_conservative_February 10, 2020_10.42.csv")

# Load in liberal data 
rt_liberal <- read_csv("rt_liberal.csv")

```

Now, I am going to clean up the data a bit and delete participants who did not pass the attention checks. 

```{r}

# Delete unnecessary rows 
rt_conservative <- rt_conservative[-(1:2),]
rt_liberal <- rt_liberal[-(1:2),]

# How many people passed the attention checks?
rt_conservative <- rt_conservative %>% 
  mutate(passed = if_else(att_1 == "Harmless (K)" & att_2 == "Immoral (J)" & att_3 == "Harmful (J)", 1, 0)) 

rt_conservative %>% 
  group_by(passed) %>% 
  summarise(n())

rt_liberal <- rt_liberal %>% 
  mutate(passed = if_else(att_1 == "Harmless (K)" & att_2 == "Immoral (J)" & att_3 == "Harmful (J)", 1, 0)) 

rt_liberal %>% 
  group_by(passed) %>% 
  summarise(n()) 


```

For the liberal sample, we got 97 responses and 5 people missed their attention checks. For the conservative sample, we got 98 responses and 6 people did not passed all attention checks. In total, then, our sample will be composed of 184 respondents. 

I am going to join both dataframes and reshape them so that we can conduct the analyses. 

```{r}

# Join both datasets 
data <- rbind(rt_liberal, rt_conservative)

# Filter people who did not pass
data <- data %>% 
  filter(passed == 1)

# Now let's turn this into a long dataframe 

# Create a manageable wide dataframe 

rtw <- data %>% 
  select(ends_with("Page Submit"), i_phc, i_pkp, i_tmdp, i_adr, i_elb, 
         i_acr, i_jbd, i_scc, i_ddf, i_git, i_idb, i_ayc, i_sip, i_ecc, 
         i_ccr, i_mbr, i_msn, i_mbw, i_php, i_mmc, i_mmls, i_msas, i_mpsa, i_whh, i_thls, h_phc, h_pkp, h_tmdp, h_adr, h_elb, 
         h_acr, h_jbd, h_scc, h_ddf, h_git, h_idb, h_ayc, h_sip, h_ecc, 
         h_ccr, h_mbr, h_msn, h_mbw, h_php, h_mmc, h_mmls, h_msas, h_mpsa, h_whh, h_thls) %>% 
  mutate(ids = 1:184) %>% 
  select(ids, everything())


# Create a long dataframe for harm and reaction time

d_long_harm_rt <- rtw %>% 
  select(ids, starts_with("h_")) %>% 
  pivot_longer(2:26, names_to = "scenario", values_to = "reaction_time_harm") %>% 
  select(ids, scenario, reaction_time_harm) %>% 
  mutate(scenario = str_remove(scenario, "_t_Page Submit$")) %>% 
  mutate(scenario = str_remove(scenario, "^h_"))

# Create a long dataframe for is_harm

d_long_harm_bin <- rtw %>% 
  select(ids, starts_with("h_")) %>% 
  pivot_longer(27:51, names_to = "scenario", values_to = "is_harmful") %>% 
  select(ids, scenario, is_harmful) %>% 
  mutate(scenario = str_remove(scenario, "^h_"))

d_long_harm <- left_join(d_long_harm_rt, d_long_harm_bin, by = c('ids', "scenario"))

# Create a long dataframe for immorality and reaction time 

d_long_imm_rt <- rtw %>% 
  select(ids, starts_with("i_")) %>% 
  pivot_longer(2:26, names_to = "scenario", values_to = "reaction_time_imm") %>% 
  select(ids, scenario, reaction_time_imm) %>% 
  mutate(scenario = str_remove(scenario, "_t_Page Submit$")) %>% 
  mutate(scenario = str_remove(scenario, "^i_"))

# Create a long dataframe for immorality and is_immoral

d_long_imm_bin <- rtw %>% 
  select(ids, starts_with("i_")) %>% 
  pivot_longer(27:51, names_to = "scenario", values_to = "is_immoral") %>% 
  select(ids, scenario, is_immoral) %>% 
  mutate(scenario = str_remove(scenario, "^i_"))

d_long_imm <- left_join(d_long_imm_rt, d_long_imm_bin, by = c('ids', 'scenario'))

# Now join them 

d_long <- left_join(d_long_harm, d_long_imm, by = c('ids', 'scenario')) %>% 
  mutate_at(c('reaction_time_harm', 'reaction_time_imm'), as.numeric)


# Let's get some information about the events in there 

# Load dataset with the deflections 

selected_events <- read_csv("data/full_events.csv")

# Create column for abreviations 

events <- c("phc", 
            "pkp", 
            "tmdp", 
            "adr", 
            "elb", 
            "acr", 
            "jbd", 
            "scc", 
            "ddf", 
            "git", 
            "idb", 
            "ayc", 
            "sip", 
            "ecc", 
            "ccr", 
            "mbr", 
            "msn", 
            "mbw", 
            "php", 
            "mmc", 
            "mmls", 
            "msas", 
            "mpsa", 
            "whh", 
            "thls")

# Create new column 

events_def <- selected_events %>% 
  mutate(scenario = events) %>% 
  select(scenario, def, type, 5:33)

# Add to long dataset 

d_long <- d_long %>% 
  left_join(events_def, by = "scenario")

```

Now, we have a more suitable dataframe. Before I begin the descriptive analysis, I am going to look for extreme values: responses that are either below 1 second or above 10. These are clearly errors and I will replace them with the median response time for the respective scenario. This approach can be revised of course, but I will use median imputation for now. 

```{r, results="hide"}

# How many weird responses do we have? 

sum(d_long$reaction_time_harm < 1)
sum(d_long$reaction_time_imm < 1)
sum(d_long$reaction_time_harm > 10)
sum(d_long$reaction_time_imm > 10)

# There are 66 responses that don't seem valid. Let's replace them with the median imputation 
# First I need to calculate the median for the scenarios 

median_rt <- d_long %>% 
  group_by(scenario) %>% 
  summarise(med_imm = median(reaction_time_imm), 
            med_harm = median(reaction_time_harm))

# Function for replacing immorality values 

replace_imm <- function(x) {
  
ss <- d_long[x, 2] %>% 
  as.vector() %>% 
  as.character()

i_scenario <- median_rt %>% 
  filter(str_detect(scenario, ss)) %>% 
  select(med_imm) %>% 
  as.numeric() %>% 
  as.vector()

d_long[x, 5] <<- i_scenario

}

# Function for replacing harm values 

replace_harm <- function(x) {
  
ss <- d_long[x, 2] %>% 
  as.vector() %>% 
  as.character()

h_scenario <- median_rt %>% 
  filter(str_detect(scenario, ss)) %>% 
  select(med_harm) %>% 
  as.numeric() %>% 
  as.vector()

d_long[x, 3] <<- h_scenario

}

# Map all small immorality values 
smaller_imm <- which(d_long$reaction_time_imm < 1)

map(.x = smaller_imm, .f = replace_imm)

# Map all small harm values 
smaller_harm <- which(d_long$reaction_time_harm < 1)

map(.x = smaller_harm, .f = replace_harm)

# Map all big immorality values 
large_imm <- which(d_long$reaction_time_imm > 10)

map(.x = large_imm, .f = replace_imm)

# Map all large harm values 
large_harm <- which(d_long$reaction_time_harm > 10)

map(.x = large_harm, .f = replace_harm)

```

We are ready to produce some descriptive plots. 

```{r}

d_long %>% 
  group_by(scenario) %>% 
  summarise(avg = mean(reaction_time_imm), 
            st_dv = sd(reaction_time_imm)) %>% 
  mutate(ci_lower = avg - 1.96*st_dv, 
         ci_upper = avg + 1.96*st_dv) %>% 
  ggplot(aes(x = reorder(scenario, avg), y = avg)) + 
  geom_point(col = "darkred", fill = "darkred") +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  coord_flip() + 
  labs(x = "", 
       y = "RT", 
       title = "Reaction Time - Immorality", 
       caption = "Circles = Mean")

d_long %>% 
  group_by(scenario) %>% 
  summarise(avg = mean(reaction_time_harm), 
            st_dv = sd(reaction_time_harm)) %>% 
  mutate(ci_lower = avg - 1.96*st_dv, 
         ci_upper = avg + 1.96*st_dv) %>% 
  ggplot(aes(x = reorder(scenario, avg), y = avg)) + 
  geom_point(col = "darkred", fill = "darkred") +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  coord_flip() + 
  labs(x = "", 
       y = "RT", 
       title = "Reaction Time - Harm", 
       caption = "Circles = Mean")

```

The confidence intervals here are quite wide, which is not very encouraging. Reaction time studies tend to be noisy so it's important to take this variation into account as we move forward. 

Again, the most prototypical scenarios have consistently the lowest reaction times, with the exception of "man betrays wife". However, there does not seem to be a strong relationship between reaction time and distance from the prototype. 

Let's see whether we can recreate Gray and Keeney's plot. 

```{r}

dsl <- d_long %>% 
  group_by(scenario, type) %>% 
  summarise(mean_harm = mean(reaction_time_harm), 
            mean_imm = mean(reaction_time_imm)) %>% 
  ungroup()


dsl %>% 
  ggplot(aes(x = mean_harm, y = mean_imm, col = type)) +
  geom_point() + 
  geom_text_repel(aes(label = scenario), show.legend = F)
```

There seems to be a strong positive relationship between reaction times in both sections. This is encouraging because it shows that the "practice effect" might not be as strong as previously expected. We can also reproduce the plot by Gray and Keeney quite reliably. I think that length and complexity are doing a lot of work here. For example, employee conspires with competitor is a complex and long sentence that has consistently high reaction time. The same applies for "married person has sex with adulterer". 

Let's look at the distribution of the reaction times more closely. 

```{r}

p_rt_imm <- d_long %>% 
  ggplot(aes(x = reaction_time_imm)) + 
  geom_histogram(binwidth = 0.1, fill = 'gray', col = "black", alpha = 0.5) + 
  labs(x = "Reaction Time", 
       y = "") 

p_rt_imm + 
  labs(title = "Reaction Times Immorality")

p_rt_imm + 
  facet_wrap(~scenario)

p_rt_harm <- d_long %>% 
  ggplot(aes(x = reaction_time_harm)) + 
  geom_histogram(binwidth = 0.1, fill = 'gray', col = "black", alpha = 0.5) + 
  labs(x = "Reaction Time", 
       y = "") 

p_rt_harm + 
  labs(title = "Reaction Times Harm")

p_rt_harm + 
  facet_wrap(~scenario)
```

The distributions of reaction times are predictably right-skewed. Most values tend to cluster around 2.5 seconds with a long tail of values covering the rest of the range. The aggregate distributions for both harm and immorality are fairly similar. When we break down the distributions by scenarios, we notice interesting patterns. The distributions of relatively ambiguous events like "athlete yells at coach" are relatively flat, exhibiting a lot of variance. In turn, the distributions of prototypical scenarios are quite clustered, signaling greater consensus. 

Now, I want to look at how individuals actually classified the each scenario. 

```{r}

# Recode variables to binary 

d_long <- d_long %>%  
  mutate(is_immoral = case_when(is_immoral == "Immoral (J)" ~ 1, 
                                is_immoral == "Not Immoral (K)" ~ 0), 
         is_harmful = case_when(is_harmful == "Harmful (J)" ~ 1, 
                                is_harmful == "Harmless (K)" ~ 0))

# Let's try to plot this 

d_long %>%  
  ggplot(aes(x = is_immoral)) + 
  geom_bar() + 
  facet_wrap(~scenario) + 
  labs( x = "Is it immoral?", 
        y = "")

d_long %>%  
  ggplot(aes(x = is_harmful)) + 
  geom_bar() + 
  facet_wrap(~scenario) + 
  labs( x = "Is it harmful?", 
        y = "")
```

Again, there are interesting patterns here. For example, there is not much disagreement around the prototypical scenarios. Around scenarios like men hiring prostitutes, however, there is almost an even split. Encouragingly, this is what we would expect. 

Let's also look at the relationship between the length of the scenario and reaction time. 

```{r}

# Name the scenarios with the full length 

dsl <- dsl %>% 
  mutate(full_string = case_when(scenario == "acr" ~ "an_athlete_cheats_their_rival", 
                                 scenario == "adr" ~ "an_athlete_deceives_the_referee", 
                                 scenario == "ayc" ~ "an_athlete_yells_at_their_coach", 
                                 scenario == "ccr" ~ "a_coach_cheers_for_the_rival", 
                                 scenario == "ddf" ~ "a_daughter_disobeys_her_father", 
                                 scenario == "ecc" ~ "an_employee_conspires_with_a_competitor", 
                                 scenario == "elb" ~ "an_employee_lies_to_the_boss", 
                                 scenario == "git" ~ "a_girl_interrupts_her_teacher", 
                                 scenario == "idb" ~ "an_intern_disobeys_their_boss", 
                                 scenario == "jbd" ~ "a_judge_befriends_the_defendant", 
                                 scenario == "mbr" ~ "a_man_betrays_his_relative", 
                                 scenario == "mbw" ~ "a_man_betrays_his_wife", 
                                 scenario == "mmc" ~ "a_man_marries_his_cousin", 
                                 scenario == "mmls" ~ "a_man_makes_love_to_his_sister", 
                                 scenario == "mpsa" ~ "a_married_man_has_sex_with_an_adulterer", 
                                 scenario == "msas" ~ "a_mother_sexually_arouses_her_son", 
                                 scenario == "msn" ~ "a_mayor_slanders_a_neighbor", 
                                 scenario == "phc" ~ "a_person_hurts_a_child", 
                                 scenario == "php" ~ "a_person_hires_a_prostitute", 
                                 scenario == "pkp" ~ "a_person_kills_a_person", 
                                 scenario == "scc" ~ "a_student_cheats_their_classmate", 
                                 scenario == "sip" ~ "a_student_insults_the_professor", 
                                 scenario == "thls" ~ "a_teacher_hits_a_lazy_student", 
                                 scenario == "whh" ~ "a_wife_hits_her_forgetful_husband", 
                                 scenario == "tmdp" ~ "a_teenager_mocks_a_disabled_person"))

# Add the short versions again for the plot

dsl <- dsl %>% 
  mutate(length = str_count(full_string))

# Now let's plot length + reaction time for immorality

dsl %>% 
  ggplot(aes(x = length, y = mean_imm, col = type)) + 
  geom_text_repel(aes(label = scenario), show.legend = F)

# Now let's plot length + reaction time for harm 

dsl %>% 
  ggplot(aes(x = length, y = mean_harm, col = type)) + 
  geom_text_repel(aes(label = scenario), show.legend = F)
```

The relationship between the length of the sentence and the reaction time is - as expected - very strong. It becomes weaker for questions about harm, presumably because at this point the respondents were already familiar with the scenarios. In the analysis, we are going to have to control for length of sentence. 

## Exploring Distances 

Now, I am going to begin looking at distances from the "prototypical" moral trangressions and will analyze whether these are informative for predicting reaction time. Let's first calculate the distances. 

```{r}

# Create function to calculate the euclidean distance in three-dimensional space 

events_values <- events_def %>% 
  select(scenario, op, be, bp)

eucl_dist_pkp <- function(x) { 
    op <-  events_values[x, 2] 
    be <-  events_values[x, 3] 
    bp <-  events_values[x, 4]
  
   # Formula   
  # The values of the prototype are always the ones the events are compared against
  distance <- sqrt((0.95 - op)^2 + ((-4.26) - be)^2 + (1.95 - bp)^2)
   return(as.double(distance))
}


distances_pkp <- map_dbl(1:25, eucl_dist_pkp)

events_values_pkp <- events_values %>% 
  cbind(distances_pkp) %>% 
  select(scenario, distances_pkp)

# Join values with the long dataset 

dsl <- dsl %>% 
  left_join(events_values_pkp, by = "scenario")

# Plot reaction time for immorality and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_pkp, y = mean_imm, col = type)) + 
  geom_point() +
  geom_text(aes(label = scenario), hjust = 0, show.legend = F) + 
  labs(x = "Distance from prototype", 
       y = "RT Immorality", 
       title = "Reaction time for immorality explained by distance from the prototype")

# Plot reaction time for harm and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_pkp, y = mean_harm, col = type)) + 
  geom_point() +
  geom_text(aes(label = scenario), hjust = 0, show.legend = F) + 
  labs(x = "Distance from prototype", 
       y = "RT Harmfulness", 
       title = "Reaction time for Harmfulness explained by distance from the prototype")

```

There does seem to be a positive association but it does not appear to be particularly strong. I am going to explore another way of defining distance: choosing a different prototype where the object is more vulnerable. As our previous analysis shows, increases in the object's potency lead to decreases in the event's severity. In this calculation, then, we are wrongly "penalizing" the scenarios that have more vulnerable patients than the one that features in our prototype - i.e. person -, which is fairly neutral. In the next part, then, I will choose "person hurts a child" as the prototype. 

```{r}

# Create new function with Person hurts child as the prototype 

eucl_dist_phc <- function(x) { 
    op <-  events_values[x, 2] 
    be <-  events_values[x, 3] 
    bp <-  events_values[x, 4]
  
   # Formula   
  # The values of the prototype are always the ones the events are compared against
  distance <- sqrt(((-1.14) - op)^2 + ((-3.17) - be)^2 + (1.06 - bp)^2)
   return(as.double(distance))
}


distances_phc <- map_dbl(1:25, eucl_dist_phc)

events_values_phc <- events_values %>% 
  cbind(distances_phc) %>% 
  select(scenario, distances_phc)

# Join values with the long dataset 

dsl <- dsl %>% 
  left_join(events_values_phc, by = "scenario")

# Plot reaction time for immorality and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_phc, y = mean_imm, col = type)) + 
  geom_point() +
  geom_text(aes(label = scenario), hjust = 0, show.legend = F) + 
  labs(x = "Distance from prototype", 
       y = "RT Immorality", 
       title = "Reaction time for immorality explained by distance from the prototype")

# Plot reaction time for harm and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_phc, y = mean_harm, col = type)) + 
  geom_point() +
  geom_text(aes(label = scenario), hjust = 0, show.legend = F) + 
  labs(x = "Distance from prototype", 
       y = "RT Harmfulness", 
       title = "Reaction time for Harmfulness explained by distance from the prototype")

# Create new function with Person hurts child as the prototype 

eucl_dist_prot <- function(x) { 
  op <-  events_values[x, 2] 
  be <-  events_values[x, 3] 
  bp <-  events_values[x, 4]
  
  # Formula   
  # The values of the prototype are always the ones the events are compared against
  distance <- sqrt(((-1.14) - op)^2 + ((-4.26) - be)^2 + (1.95 - bp)^2)
  return(as.double(distance))
}


distances_prot <- map_dbl(1:25, eucl_dist_prot)

events_values_prot <- events_values %>% 
  cbind(distances_prot) %>% 
  select(scenario, distances_prot)

# Join values with the long dataset 

dsl <- dsl %>% 
  left_join(events_values_prot, by = "scenario")

```


If we calculate distance from "person hurts a child", we also get positive associations. Now, that we have these distances we can try to see the correlations between all the variables of interest. 

```{r}

# Let's first tidy the data a bit 
# Get the lengths and put them in the main dataset 

lengths <- dsl %>% 
  select(scenario, length, distances_phc, distances_pkp, distances_prot)

d_long <- d_long %>% 
  select(1:16) %>% 
  left_join(lengths, by = "scenario")

# Add one column for the average reaction time of the person 

# Create the averages 
avg_rt <- d_long %>% 
  select(ids, reaction_time_harm, reaction_time_imm) %>% 
  pivot_longer(2:3) %>% 
  group_by(ids) %>% 
  summarise(avg_rt = mean(value))

# Add averages to long data 

d_long <- left_join(d_long, avg_rt, by = "ids")

d_long %>% 
  select(-c(1, 2, 4, 6, 8, 9:16)) %>% 
  mutate_all(as.numeric) %>% 
  cor() %>% 
  corrplot(method = "number")
```

The correlation plot shows that the raw relationship between distances and reaction time is very small. I am now going to conduct more principled statistical analyses, but these correlations suggests that relationships will be hard to find. 

## Preliminary models 

Let's try to see how some preliminary regressions would look like. 

```{r}

# Add ideological beliefs

data_pol <- data %>% 
  select(ideology_1) %>% 
  mutate(ids = 1:184)

d_long <- left_join(d_long, data_pol, by = "ids")

# Scale the dataframe 

d_long_scaled <- 
  d_long %>% 
  mutate_at(c("ids", "type", "scenario", "is_immoral", "is_harmful", "ideology_1"), ~as.factor(.)) %>% 
  mutate_if(is.numeric, scale)

# Now let's some models 

# First let's check the relationship between immorality and harm 

m1 <- lmer(reaction_time_harm ~ 1 + reaction_time_imm + length + (1 | ids) + (1 | scenario) + avg_rt,
           data = d_long_scaled)

tab_model(m1, p.val = ("kr"))

m2 <- lmer(reaction_time_imm ~ 1 + reaction_time_harm + length + (1 | ids) + (1 | scenario) + avg_rt,
           data = d_long_scaled)

tab_model(m2, p.val = ("kr"))

m3 <- lmer(reaction_time_imm ~ 1 + distances_phc + length + (1 | ids) + (1 | scenario) + reaction_time_harm,
           data = d_long_scaled)

tab_model(m3, p.val = ("kr"))

m4 <- lmer(reaction_time_harm ~ 1 + distances_phc + length + (1 | ids) + (1 | scenario) + reaction_time_imm,
           data = d_long_scaled)

tab_model(m4, p.val = ("kr"))

m5 <- glmer(is_immoral ~ 1 + distances_phc + length + (1 | ids) + (1 | scenario) + reaction_time_imm + reaction_time_harm,
           data = d_long_scaled, 
           family = binomial)

tab_model(m5, p.val = ("kr"))

m6 <- glmer(is_harmful ~ 1 + distances_phc + length + (1 | ids) + (1 | scenario) + reaction_time_imm + reaction_time_harm,
           data = d_long_scaled, 
           family = binomial)

tab_model(m6, p.val = ("kr"))

```

We notice some predictable results. Reaction time for harmfulness is highly predictive of reaction time of immorality and vice versa. These relationships hold even if we control for the respondents' average reaction time. Although distance from the prototype appears to have a positive relationship with reaction-time, the coefficient does not reach significance. 

The last two models are logistic regressions that predict the probability of categorizing an event as immoral or harmful. Here, we also notice expected relationships: as distance from the prototype gets larger, the probability of classifying an event as either immoral or harmful is reduced. However, the coefficient for distance only reaches significance in the model that predicts classification of harm. 