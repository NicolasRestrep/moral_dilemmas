---
title: "Reaction Time - Liberals"
author: "Nicolas Restrepo"
date: "1/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analysis of the Reaction Time Study (Liberal Sample)

```{r, message=FALSE}
# Packages 
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggrepel)
library(gridExtra)
library(haven)
library(lavaan)
library(lme4)
library(nlme)
library(stargazer)
library(broom)
library(psych)
library(brms)
library(plotly)
library(sjPlot)
theme_set(theme_light())
```

I'm going to begin by loading in the data. 

```{r, message = FALSE}
# Load in the data 
rt_liberal <- read_csv("rt_liberal.csv")
```

As a first step I am going to check how people did in the attention checks. 

```{r}
# Delete unnecessary rows
rt_liberal <- rt_liberal[-(1:2),]

# How many people passed the attention checks?
rt_liberal <- rt_liberal %>% 
  mutate(passed = if_else(att_1 == "Harmless (K)" & att_2 == "Immoral (J)" & att_3 == "Harmful (J)", 1, 0)) 

rt_liberal %>% 
  group_by(passed) %>% 
  summarise(n()) 

# Filter out the people who failed the attention checks 
rt_liberal <- rt_liberal %>% 
  filter(passed == 1)
```

From the 100 surveys I sent out, 97 were completed. There were three in which the respondents reported technical problems. From these 97 respondents, 92 passed all the attention checks. I am going to go ahead and continue this preliminary analysis with these 92 cases. 

Now, I am going to run some quick diagnostics. I am mostly looking for overly short responses, which would indicate either a misclick or random key stroke. Before that I will do a fair amount of reshaping. 

```{r}

# Only keep reaction time data and put it in the long format 
rt_liberal_times <- rt_liberal %>% 
  select(ends_with("Page Submit")) %>% 
  mutate(ids = 1:92) %>% 
  pivot_longer(1:50, names_to = "scenario", values_to = "reaction_time") %>% 
  mutate(scenario = str_remove(scenario, "_t_Page Submit$"))

# Get summary statistics 
gd <- rt_liberal_times %>% 
  mutate(reaction_time = as.numeric(reaction_time)) %>% 
  group_by(scenario) %>% 
  summarise(avg = mean(reaction_time), 
            st_dv = sd(reaction_time),
            med = median(reaction_time)) %>% 
  mutate(ci_lower = avg - 1.96*st_dv, 
         ci_upper = avg + 1.96*st_dv)

# Create a quick summary table
rt_liberal_times %>% 
  mutate(reaction_time = as.numeric(reaction_time)) %>% 
  summarise(avg = mean(reaction_time), 
            stv = sd(reaction_time)) %>% 
  mutate(ci_lower = avg - 1.96*stv, 
         ci_upper = avg + 1.96*stv) %>% 
  kable(.) %>% 
  kable_styling()

# Now check for exceedingly low responses 
sum(rt_liberal_times$reaction_time < 1)
sum(rt_liberal_times$reaction_time > 5.58)
sum(rt_liberal_times$reaction_time > 9)
```

I need to think more about what to do with the observations that are considerably above the mean (for example those above 9). However, I am pretty sure that those 4 observations under a second are misclicks. I will go ahead replace their values for the median of their respective scenario. There is probably a more informed way to do this, but I think this will suffice for the preliminary analysis.  


```{r}
# Which are the responses below 1 second?
which(rt_liberal_times$reaction_time < 1)

# Replace them with the appropriate median
rt_liberal_times[767,] <- gd[gd$scenario=="i_ccr",4]
rt_liberal_times[1119,] <- gd[gd$scenario=="i_msn",4]
rt_liberal_times[1514,] <- gd[gd$scenario=="i_ayc",4]
rt_liberal_times[2757,] <- gd[gd$scenario=="i_elb",4]
```

Having replaced those values, I am going to produce some descriptive plots. 

```{r}
# Now let's plot harm 

# Keep only harm questions 

gdh <- gd[str_which(gd$scenario, "h_"),]

# Plot harm questions 
gdh %>% 
  mutate(scenario = str_remove(scenario, "h_")) %>% 
  ggplot(aes(x = reorder(scenario, avg), y = avg)) + 
  geom_point(col = "darkred", fill = "darkred") +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  coord_flip() + 
  labs(x = "", 
       y = "RT", 
       title = "Reaction Time - Harmfulness", 
       caption = "Circles = Mean")

# Get only Immorality questions 
gdi <- gd[str_which(gd$scenario, "i_"),]

# Plot harm questions 
gdi %>% 
  mutate(scenario = str_remove(scenario, "i_")) %>% 
  ggplot(aes(x = reorder(scenario, avg), y = avg)) + 
  geom_point(col = "darkred", fill = "darkred") + 
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  coord_flip() + 
  labs(x = "", 
       y = "RT", 
       title = "Reaction Time - Immorality",
       caption = "Circles = Mean")

```

At first glance, the confidence intervals look quite wide. It is important to think whether the variation in the data is coming from real empirical variability or whether the instrument is too noisy. I certainly need to spend more time thinking about the latter. 

Another aspect that worries me is some kind of "practice effect". In the survey, questions about immorality come before questions of harm. If we look at "mother sexually arouses son", it has one of the highest average reaction time in immorality. However, when it comes to harm, it has the 4th lowest. This might be because, at first, it took a while for respondents to read and understand the sentence. By the second time, their minds were made up. I will explore this more below. 

The most prototypical scenarios have consistently the lowest reaction times. However, at this point, it does not seem that distance from the prototype would be very informative when predicting reaction time. Let's dig deeeper. 


Let's try to recreate Gray and Keeney's reaction time plot. 

```{r}

# Create a manageable wide dataframe 

rtw <- rt_liberal %>% 
  select(ends_with("Page Submit"), i_phc, i_pkp, i_tmdp, i_adr, i_elb, 
         i_acr, i_jbd, i_scc, i_ddf, i_git, i_idb, i_ayc, i_sip, i_ecc, 
         i_ccr, i_mbr, i_msn, i_mbw, i_php, i_mmc, i_mmls, i_msas, i_mpsa, i_whh, i_thls, h_phc, h_pkp, h_tmdp, h_adr, h_elb, 
         h_acr, h_jbd, h_scc, h_ddf, h_git, h_idb, h_ayc, h_sip, h_ecc, 
         h_ccr, h_mbr, h_msn, h_mbw, h_php, h_mmc, h_mmls, h_msas, h_mpsa, h_whh, h_thls) %>% 
  mutate(ids = 1:92) %>% 
  select(ids, everything())


# Create a long dataframe for harm and reaction time

d_long_harm_rt <- rtw %>% 
  select(ids, starts_with("h_")) %>% 
  pivot_longer(2:26, names_to = "scenario", values_to = "reaction_time_harm") %>% 
  select(ids, scenario, reaction_time_harm) %>% 
  mutate(scenario = str_remove(scenario, "_t_Page Submit$")) %>% 
  mutate(scenario = str_remove(scenario, "^h_"))

# Create a long dataframe for is_harm

d_long_harm_bin <- rtw %>% 
  select(ids, starts_with("h_")) %>% 
  pivot_longer(27:51, names_to = "scenario", values_to = "is_harmful") %>% 
  select(ids, scenario, is_harmful) %>% 
  mutate(scenario = str_remove(scenario, "^h_"))

d_long_harm <- left_join(d_long_harm_rt, d_long_harm_bin, by = c('ids', "scenario"))

# Create a long dataframe for immorality and reaction time 

d_long_imm_rt <- rtw %>% 
  select(ids, starts_with("i_")) %>% 
  pivot_longer(2:26, names_to = "scenario", values_to = "reaction_time_imm") %>% 
  select(ids, scenario, reaction_time_imm) %>% 
  mutate(scenario = str_remove(scenario, "_t_Page Submit$")) %>% 
  mutate(scenario = str_remove(scenario, "^i_"))

# Create a long dataframe for immorality and is_immoral

d_long_imm_bin <- rtw %>% 
  select(ids, starts_with("i_")) %>% 
  pivot_longer(27:51, names_to = "scenario", values_to = "is_immoral") %>% 
  select(ids, scenario, is_immoral) %>% 
  mutate(scenario = str_remove(scenario, "^i_"))

d_long_imm <- left_join(d_long_imm_rt, d_long_imm_bin, by = c('ids', 'scenario'))

# Now join them 

d_long <- left_join(d_long_harm, d_long_imm, by = c('ids', 'scenario')) %>% 
  mutate_at(c('reaction_time_harm', 'reaction_time_imm'), as.numeric)

# Replace < 1 values here 

which(d_long$reaction_time_imm < 1)
which(d_long$reaction_time_harm < 1)

d_long[392,5] <- gd[gd$scenario=="i_ccr",4]
d_long[569,5] <- gd[gd$scenario=="i_msn",4]
d_long[764,5] <- gd[gd$scenario=="i_ayc",4]
d_long[1382,5] <- gd[gd$scenario=="i_elb",4]



# Let's get some information about the events in there 

# Load dataset with the deflections 

selected_events <- read_csv("data/full_events.csv")

# Create column for abreviations 

events <- c("phc", 
            "pkp", 
            "tmdp", 
            "adr", 
            "elb", 
            "acr", 
            "jbd", 
            "scc", 
            "ddf", 
            "git", 
            "idb", 
            "ayc", 
            "sip", 
            "ecc", 
            "ccr", 
            "mbr", 
            "msn", 
            "mbw", 
            "php", 
            "mmc", 
            "mmls", 
            "msas", 
            "mpsa", 
            "whh", 
            "thls")

# Create new column 

events_def <- selected_events %>% 
  mutate(scenario = events) %>% 
  select(scenario, def, type, 5:33)

# Add to long dataset 

d_long <- d_long %>% 
  left_join(events_def, by = "scenario")

# Get the averages so we can plot them 

dsl <- d_long %>% 
  group_by(scenario, type) %>% 
  summarise(mean_harm = mean(reaction_time_harm), 
            mean_imm = mean(reaction_time_imm)) %>% 
  ungroup()


dsl %>% 
  ggplot(aes(x = mean_harm, y = mean_imm, col = type)) +
  geom_point() + 
  geom_text_repel(aes(label = scenario), show.legend = F)
```

There seems to be a strong positive relationship between reaction times in both sections. This is encouraging because it shows that the "practice effect" might not be as strong as previously expected. We can also reproduce the plot by Gray and Keeney quite reliably. I still think that length and complexity are doing a lot of work here. For example, employee conspires with competitor is a complex and long sentence that has consistently high reaction time. The same applies for "married person has sex with adulterer". 

Let's look at the distribution of the reaction times more closely. 

```{r}

p_rt_imm <- d_long %>% 
  ggplot(aes(x = reaction_time_imm)) + 
  geom_histogram(binwidth = 0.1, fill = 'gray', col = "black", alpha = 0.5) + 
  labs(x = "Reaction Time", 
       y = "") 

p_rt_imm + 
  labs(title = "Reaction Times Immorality")

p_rt_imm + 
  facet_wrap(~scenario)

p_rt_harm <- d_long %>% 
  ggplot(aes(x = reaction_time_harm)) + 
  geom_histogram(binwidth = 0.1, fill = 'gray', col = "black", alpha = 0.5) + 
  labs(x = "Reaction Time", 
       y = "") 

p_rt_harm + 
  labs(title = "Reaction Times Harm")

p_rt_harm + 
  facet_wrap(~scenario)
```

The distributions of reaction times are predictably right-skewed. Most values tend to cluster around 2.5 seconds with a long tail of values covering the rest of the range. The aggregate distributions for both harm and immorality are fairly similar. When we break down the distributions by scenarios, we notice interesting patterns. The distributions of relatively ambiguous events like "athlete yells at coach" are relatively flat, exhibiting a lot of variance. In turn, the distributions of prototypical scenarios are quite clustered, signaling greater consensus. 

Now, I want to look at how individuals actually classified the each scenario. 

```{r}

# Recode variables to binary 

d_long <- d_long %>%  
  mutate(is_immoral = case_when(is_immoral == "Immoral (J)" ~ 1, 
                                is_immoral == "Not Immoral (K)" ~ 0), 
         is_harmful = case_when(is_harmful == "Harmful (J)" ~ 1, 
                                is_harmful == "Harmless (K)" ~ 0))

# Let's try to plot this 

d_long %>%  
  ggplot(aes(x = is_immoral)) + 
  geom_bar() + 
  facet_wrap(~scenario) + 
  labs( x = "Is it immoral?", 
        y = "")

d_long %>%  
  ggplot(aes(x = is_harmful)) + 
  geom_bar() + 
  facet_wrap(~scenario) + 
  labs( x = "Is it harmful?", 
        y = "")
```

Again, there are interesting patterns here. For example, there is not much disagreement around the prototypical scenarios. Around scenarios like men marrying their cousing or hiring prostitutes there is much more disagreement. This is what we would expect. 


I want to check how length correlates with reaction time. 

```{r}

# Name the scenarios with the full length 

dsl <- dsl %>% 
  mutate(full_string = case_when(scenario == "acr" ~ "an_athlete_cheats_their_rival", 
                                 scenario == "adr" ~ "an_athlete_deceives_the_referee", 
                                 scenario == "ayc" ~ "an_athlete_yells_at_their_coach", 
                                 scenario == "ccr" ~ "a_coach_cheers_for_the_rival", 
                                 scenario == "ddf" ~ "a_daughter_disobeys_her_father", 
                                 scenario == "ecc" ~ "an_employee_conspires_with_a_competitor", 
                                 scenario == "elb" ~ "an_employee_lies_to_the_boss", 
                                 scenario == "git" ~ "a_girl_interrupts_her_teacher", 
                                 scenario == "idb" ~ "an_intern_disobeys_their_boss", 
                                 scenario == "jbd" ~ "a_judge_befriends_the_defendant", 
                                 scenario == "mbr" ~ "a_man_betrays_his_relative", 
                                 scenario == "mbw" ~ "a_man_betrays_his_wife", 
                                 scenario == "mmc" ~ "a_man_marries_his_cousin", 
                                 scenario == "mmls" ~ "a_man_makes_love_to_his_sister", 
                                 scenario == "mpsa" ~ "a_married_man_has_sex_with_an_adulterer", 
                                 scenario == "msas" ~ "a_mother_sexually_arouses_her_son", 
                                 scenario == "msn" ~ "a_mayor_slanders_a_neighbor", 
                                 scenario == "phc" ~ "a_person_hurts_a_child", 
                                 scenario == "php" ~ "a_person_hires_a_prostitute", 
                                 scenario == "pkp" ~ "a_person_kills_a_person", 
                                 scenario == "scc" ~ "a_student_cheats_their_classmate", 
                                 scenario == "sip" ~ "a_student_insults_the_professor", 
                                 scenario == "thls" ~ "a_teacher_hits_a_lazy_student", 
                                 scenario == "whh" ~ "a_wife_hits_her_forgetful_husband", 
                                 scenario == "tmdp" ~ "a_teenager_mocks_a_disabled_person"))

# Add the short versions again for the plot

dsl <- dsl %>% 
  mutate(length = str_count(full_string))

# Now let's plot length + reaction time for immorality

dsl %>% 
  ggplot(aes(x = length, y = mean_imm, col = type)) + 
  geom_text_repel(aes(label = scenario), show.legend = F)

# Now let's plot length + reaction time for harm 

dsl %>% 
  ggplot(aes(x = length, y = mean_harm, col = type)) + 
  geom_text_repel(aes(label = scenario), show.legend = F)
```

The relationship between the length of the sentence and the reaction time is - as expected - very strong. It becomes weaker for questions about harm, presumably because at this point the respondents were already familiar with the scenarios. In the analysis, we are going to have to control for length of sentence. 

## Exploring Distances 

Now, I am going to begin looking at distances from the "prototypical" moral trangressions and will analyze whether these are informative for predicting reaction time. Let's first calculate the distances. 

```{r}

# Create function to calculate the euclidean distance in three-dimensional space 

events_values <- events_def %>% 
  select(scenario, op, be, bp)

eucl_dist_pkp <- function(x) { 
    op <-  events_values[x, 2] 
    be <-  events_values[x, 3] 
    bp <-  events_values[x, 4]
  
   # Formula   
  # The values of the prototype are always the ones the events are compared against
  distance <- sqrt((0.95 - op)^2 + ((-4.26) - be)^2 + (1.95 - bp)^2)
   return(as.double(distance))
}


distances_pkp <- map_dbl(1:25, eucl_dist_pkp)

events_values_pkp <- events_values %>% 
  cbind(distances_pkp) %>% 
  select(scenario, distances_pkp)

# Join values with the long dataset 

dsl <- dsl %>% 
  left_join(events_values_pkp, by = "scenario")

# Plot reaction time for immorality and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_pkp, y = mean_imm, col = type)) + 
  geom_point() +
  geom_text(aes(label = scenario), hjust = 0, show.legend = F) + 
  labs(x = "Distance from prototype", 
       y = "RT Immorality", 
       title = "Reaction time for immorality explained by distance from the prototype")

# Plot reaction time for harm and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_pkp, y = mean_harm, col = type)) + 
  geom_point() +
  geom_text(aes(label = scenario), hjust = 0, show.legend = F) + 
  labs(x = "Distance from prototype", 
       y = "RT Harmfulness", 
       title = "Reaction time for Harmfulness explained by distance from the prototype")

```

There does seem to be a positive association but it does not appear to be particularly strong. I am going to explore another way of defining distance: choosing a different prototype where the object is more vulnerable. As our previous analysis shows, increases in the object's potency lead to decreases in the event's severity. In this calculation, then, we are wrongly "penalizing" the scenarios that have more vulnerable patients than the one that features in our prototype - i.e. person -, which is fairly neutral. In the next part, then, I will choose "person hurts a child" as the prototype. 

```{r}

# Create new function with Person hurts child as the prototype 

eucl_dist_phc <- function(x) { 
    op <-  events_values[x, 2] 
    be <-  events_values[x, 3] 
    bp <-  events_values[x, 4]
  
   # Formula   
  # The values of the prototype are always the ones the events are compared against
  distance <- sqrt(((-1.14) - op)^2 + ((-3.17) - be)^2 + (1.06 - bp)^2)
   return(as.double(distance))
}


distances_phc <- map_dbl(1:25, eucl_dist_phc)

events_values_phc <- events_values %>% 
  cbind(distances_phc) %>% 
  select(scenario, distances_phc)

# Join values with the long dataset 

dsl <- dsl %>% 
  left_join(events_values_phc, by = "scenario")

# Plot reaction time for immorality and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_phc, y = mean_imm, col = type)) + 
  geom_point() +
  geom_text(aes(label = scenario), hjust = 0, show.legend = F) + 
  labs(x = "Distance from prototype", 
       y = "RT Immorality", 
       title = "Reaction time for immorality explained by distance from the prototype")

# Plot reaction time for harm and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_phc, y = mean_harm, col = type)) + 
  geom_point() +
  geom_text(aes(label = scenario), hjust = 0, show.legend = F) + 
  labs(x = "Distance from prototype", 
       y = "RT Harmfulness", 
       title = "Reaction time for Harmfulness explained by distance from the prototype")

```

If we calculate distance from "person hurts a child", we also get positive associations. Now, that we have these distances we can try to run some models with them. 

## Preliminary models 

Let's try to see how some preliminary regressions would look like. 

```{r}

# Let's first tidy the data a bit 
# Get the lengths and put them in the main dataset 

lengths <- dsl %>% 
  select(scenario, length, distances_phc, distances_pkp)

d_long <- d_long %>% 
  select(1:16) %>% 
  left_join(lengths, by = "scenario")

# Add one column for the average reaction time of the person 

# Create the averages 
avg_rt <- d_long %>% 
  select(ids, reaction_time_harm, reaction_time_imm) %>% 
  pivot_longer(2:3) %>% 
  group_by(ids) %>% 
  summarise(avg_rt = mean(value))

# Add averages to long data 

d_long <- left_join(d_long, avg_rt, by = "ids")

# Scale the dataframe 

d_long_scaled <- 
  d_long %>% 
  mutate_at(c("ids", "type", "scenario", "is_immoral", "is_harmful"), ~as.factor(.)) %>% 
  mutate_if(is.numeric, scale)

# Now let's some models 
#first let's check the relationship between immorality and harm 

m1 <- lmer(reaction_time_harm ~ 1 + reaction_time_imm + length + (1 | ids) + (1 | scenario),
           data = d_long_scaled)

tab_model(m1, p.val = ("kr"))

m2 <- lmer(reaction_time_imm ~ 1 + reaction_time_harm + length + (1 | ids) + (1 | scenario),
           data = d_long_scaled)

tab_model(m2, p.val = ("kr"))

m3 <- lmer(reaction_time_imm ~ 1 + distances_phc + length + (1 | ids) + (1 | scenario) + reaction_time_harm,
           data = d_long_scaled)

tab_model(m3, p.val = ("kr"))

m4 <- lmer(reaction_time_harm ~ 1 + distances_phc + length + (1 | ids) + (1 | scenario) + reaction_time_imm,
           data = d_long_scaled)

tab_model(m4, p.val = ("kr"))

```

I want to draw attention to a couple of things here. First, reaction time of harm reliably predicts reaction time in immorality. This is not trivial. Given that harm comes later, this coefficient tells us that the practice effect is perhaps not as strong as previously thought. Maybe the instrument is getting at some underlying opinions, beyond reading ability and familiarity with the instrument. 

Distance from the vulnerable prototype seems to have the predicted effect on reaction time. Though not significant in both instances, the confidence intervals suggest that the values lies above zero. This is even after we control for length. I find this quite encouraging. 
