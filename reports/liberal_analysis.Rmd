---
title: "Liberal Analysis"
author: "Nicolas Restrepo"
date: "11/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```

## Preliminary analysis of the liberal data 

```{r}
# Packages 
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggrepel)
library(gridExtra)
library(haven)
library(lavaan)
library(lme4)
library(nlme)
library(stargazer)
library(broom)
library(psych)
library(brms)
theme_set(theme_light())
```

### Data Preparation 

I am going to begin by loading the data. We get two different data sources so we need to merge them.  

```{r}
# Load the data in 

second_data <- read_csv("liberals_complete.csv")

# Get rid of the first two rows which are uninformative 

second_data <- second_data[-(1:2), ]

# Load in data from the first batch 

p_data <- read_csv("pretest.csv")

p_data <- p_data[-(1:3), ]

# Now bind them together 

data <- rbind(second_data, p_data)

```

Everything seems okay. We have 105 observations but this is before we filter for people who are not liberal and who did not pass the attention checks. 

Let's begin by filtering the respondents who fail the attention checks. 

```{r}

# Get attention checks for the data 

data <- data %>% 
  mutate(passed_1 = ifelse(ach_1_1 == "extremely harmful", 1, 0), 
         passed_2 = ifelse(ach_2_1 == "not at all immoral", 1, 0), 
         passed_3 = ifelse(ach_3_1 == "moderately unexpected", 1, 0), 
         passed_4 = ifelse(ach_4_1 == "not at all harmful", 1, 0), 
         passed_5 = ifelse(ach_5_1 == "extremely immoral", 1, 0), 
         passed_6 = ifelse(ach_6_1 == "extremely unexpected", 1, 0), 
         sum_pass = passed_1 + passed_2 + passed_3 + passed_4 + passed_5 + passed_6)


# Now drop cases which did not pass the attention checks 

data <- data %>% 
  filter(sum_pass == 6)

```

Now, let's make sure we only have liberals in the sample.

```{r}
# Create variable that indicates if someone is liberal

data <- data %>% 
  mutate(liberal = ifelse(ideology_1 == 1 | ideology_1 == 2 | ideology_1 == 3, 1, 0)) 

# Drop participants who are not liberal 

data <- data %>% 
  filter(liberal == 1)

```

In total, we have 99 usable observations. 

I am also going to recode the data so we get numbers instead of strings. 

```{r}

# Mutate all main questions so that we get numbers 

data <- data %>% 
  mutate_at(vars(contains("_h_1")), funs(recode(., 
                                   "not at all harmful" = 1, 
                                   "slightly harmful" = 2, 
                                   "moderately harmful" = 3, 
                                   "very harmful" = 4, 
                                   "extremely harmful" = 5))) %>% 
  mutate_at(vars(contains("_i_1")), funs(recode(., 
                                   "not at all immoral" = 1, 
                                   "slightly immoral" = 2, 
                                   "moderately immoral" = 3, 
                                   "very immoral" = 4, 
                                   "extremely immoral" = 5))) %>% 
  mutate_at(vars(contains("_u_1")), funs(recode(., 
                                   "not at all unexpected" = 1, 
                                   "slightly unexpected" = 2, 
                                   "moderately unexpected" = 3, 
                                   "very unexpected" = 4, 
                                   "extremely unexpected" = 5)))
  
  
```

For now, I am going to select only the ratings for each event (no demographic questions):

```{r}

# Get of of the first set of uninformative columns 

d <- data %>% 
  select(-contains("ach")) %>% 
  select(pkp_h_1:msas_u_1)

# Now let's create a more amenable dataset 

d <- d %>% 
  mutate(id = 1:n()) %>% 
  select(id, everything()) 

# Rename all variables 

d <- d %>%  
  rename_all(
    funs(str_remove(., "_1"))
    ) %>% 
  mutate_if(is.character, as.numeric)

```

At this point, it is also useful to put the data into a long format for multilevel analysis and in order to create certain visualizations. 

```{r}

# Reshape harmful perceptions from wide to long 

d_harm_long <- d %>% 
  select(id, contains("_h")) %>% 
  gather(key = "scenario", value = "harm", 2:26) %>% 
  mutate(scenario = str_remove(scenario, "_h$"))

# Reshape immoral perceptions from wide to long 

d_imm_long <- d %>% 
  select(id, contains("_i")) %>% 
  gather(key = "scenario", value = "immoral", 2:26) %>% 
  mutate(scenario = str_remove(scenario, "_i$"))

# Reshape unexpected perceptions from wide to long 

d_un_long <- d %>% 
select(id, contains("_u")) %>% 
  gather(key = "scenario", value = "unexpected", 2:26) %>% 
  mutate(scenario = str_remove(scenario, "_u$"))

# Now join them 

d_long <- d_harm_long %>% 
  mutate(immoral = d_imm_long$immoral, 
         unexpected = d_un_long$unexpected)
```

Now I am going to create a column for each moral foundation and I will also add the deflection to each event. 

```{r}

# Load dataset with the deflections 

selected_events <- read_csv("selected_events.csv")

# Create column for abreviations 

events <- c("pch", 
            "pkp", 
            "tmdp", 
            "adr", 
            "elb", 
            "acr", 
            "jbd", 
            "scc", 
            "ddf", 
            "git", 
            "idb", 
            "ayc", 
            "sip", 
            "ecc", 
            "ccr", 
            "mbr", 
            "msn", 
            "mbw", 
            "php", 
            "mmc", 
            "mmls", 
            "msas", 
            "mpsa", 
            "whh", 
            "thls")

# Create new column 

events_def <- selected_events %>% 
  mutate(scenario = events) %>% 
  select(scenario, def, type)

# Add to long dataset 

d_long <- d_long %>% 
  left_join(events_def, by = "scenario")
```

## Descriptive Analysis 

I am going to make some descriptive plots for the average scores for each question on all three dimensions. To do this I first need to create a summary table. 

```{r}

# create a summary table for the values of each question 

gd <- d %>% 
  select(-id) %>% 
  gather(key = "scenario", 
         value = "score") %>% 
  group_by(scenario) %>% 
  summarise_all(funs(avg = mean(.), med = median(.), maximum = max(.), minimum = min(.), st_dv = sd(.))) %>% 
  mutate(ci_lower = avg - 1.96*st_dv, 
         ci_upper = avg + 1.96*st_dv) 

gd <- gd %>% 
  mutate(scenario = str_replace(scenario, "acr", "athlete_cheats_rival"), 
         scenario = str_replace(scenario, "adr", "athlete_deceives_referee"), 
         scenario = str_replace(scenario, "ayc", "athlete_yells_at_coach"), 
         scenario = str_replace(scenario, "ccr", "coach_cheers_rival"), 
         scenario = str_replace(scenario, "ddf", "daughter_disobeys_father"),
         scenario = str_replace(scenario, "ecc", "employee_conspires_with_comp."),
         scenario = str_replace(scenario, "elb", "employee_lies_to_boss"), 
         scenario = str_replace(scenario, "git", "girl_interrupts_teacher"),
         scenario = str_replace(scenario, "idb", "intern_disobeys_boss"), 
         scenario = str_replace(scenario, "jbd", "judge_befriends_defendant"), 
         scenario = str_replace(scenario, "mbr", "man_betrays_relative"), 
         scenario = str_replace(scenario, "mbw", "man_betrays_wife"), 
         scenario = str_replace(scenario, "mmc", "man_marries_cousin"),
         scenario = str_replace(scenario, "mmls", "man_makes_love_sister"), 
         scenario = str_replace(scenario, "mpsa", "married_has_sex_adulterer"), 
         scenario = str_replace(scenario, "msas", "mother_sexually_arouses_son"), 
         scenario = str_replace(scenario, "msn", "mayor_slanders_neighbor"), 
         scenario = str_replace(scenario, "pch", "person_hurts_child"), 
         scenario = str_replace(scenario, "php", "person_hires_prostitute"), 
         scenario = str_replace(scenario, "pkp", "person_kills_person"),
         scenario = str_replace(scenario, "scc", "student_cheats_classmate"), 
         scenario = str_replace(scenario, "sip", "student_insults_professor"), 
         scenario = str_replace(scenario, "thls", "teacher_hits_lazy_student"), 
         scenario = str_replace(scenario, "whh", "wife_hits_husband"), 
         scenario = str_replace(scenario, "tmdp", "teenager_mocks_disabled"))
```


Now that we have the table, we can produce the plots. 

```{r}

# Keep only harm questions 

gdh <- gd[str_which(gd$scenario, "_h$"),]

# Plot harm questions 

gdh %>% 
  mutate(scenario = str_remove(scenario, "_h$")) %>% 
  ggplot(aes(x = reorder(scenario, avg), y = avg)) + 
  geom_point(col = "darkred", fill = "darkred") + 
  geom_point(aes( y = med), col = "darkgreen", pch = 2) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  coord_flip() + 
  labs(x = "", 
       y = "Ratings", 
       title = "Perceptions of Harmfulness", 
       caption = "Circles = Mean \nTriangles = Median")

# Now lets look at immorality 

gdi <- gd[str_which(gd$scenario, "_i$"),]

# Plot immorality

gdi %>% 
  mutate(scenario = str_remove(scenario, "_i$")) %>% 
  ggplot(aes(x = reorder(scenario, avg), y = avg)) + 
  geom_point(col = "darkred", fill = "darkred") + 
  geom_point(aes( y = med), col = "darkgreen", pch = 2) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  coord_flip() + 
  labs(x = "", 
       y = "Ratings", 
       title = "Perceptions of Immorality", 
       caption = "Circles = Mean \nTriangles = Median")

# Lastly let's look at unexpectedness 

gdu <- gd[str_which(gd$scenario, "_u$"),]

# Plot Unexpectedness

gdu %>% 
  mutate(scenario = str_remove(scenario, "_u$")) %>% 
  ggplot(aes(x = reorder(scenario, avg), y = avg)) + 
  geom_point(col = "darkred", fill = "darkred") + 
  geom_point(aes( y = med), col = "darkgreen", pch = 2) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  coord_flip() + 
  labs(x = "", 
       y = "Ratings", 
       title = "Perceptions of Unexpectedness", 
       caption = "Circles = Mean \nTriangles = Median")

```

These plots are interesting. In general, they show the trends that we expected: the most obviously harmful events are those on top of the harmfulness scale and the same goes for the most obviously unexpected events. In this sense, the results are encouraging. 

I am a bit concerned about the relatively wide confidence intervals. However, the spread of the data is interesting as well. For example, let's look at the harmfulness ratings for "man marries cousin" and "man makes love to his sister". The confidence intervals are quite wide. This is interesting because it suggests that there is quite a lot of disagreement about how harmful these events are. This speaks directly to Kurt's theory - debates about the gravity of purity transgressions might be related to the fact that we differ in the extent to which we consider these acts harmful. This is an interesting insight in itself. 

We are also capable of recreating the plot from Gray and Keeney (2015), where they visualize the average severity of events and their "weirdness". In the next plot, then, I will put immorality in the x-axis and unexpectedness in the y-axis. 


```{r}

# create mean measures from the long dataset

dsl <- d_long %>% 
  group_by(scenario, type, def) %>% 
  summarise(mean_harm = mean(harm), 
            mean_imm = mean(immoral), 
            mean_unex = mean(unexpected)) 


# Recreate Gray and Keeney's plot

dsl %>% 
  ggplot(aes(x = mean_imm, y = mean_unex, col = type)) + 
  geom_point() + 
  geom_text_repel(aes(label = scenario), show.legend = F) + 
  theme(legend.position = "bottom") + 
  guides(text = F) + 
  labs(x = "Immorality", 
       y = "Unexpectedness", 
       title = "Average Unexpectedness by Average Immorality",
       subtitle = "Liberal Sub-sample")

```

This actually looks similar to what Gray and Keeney found. Some of he "purity" violations are consistently regarded as more unexpected than the rest of the transgressions. However, our data show that unexpectedness is quite highly correlated with immorality, which is a point that Gray and Keeney make but cannot really prove. 

Let's look at the relationship between harm and unexpectedness, and harm and immorality. 

```{r}

# Plot harm by unexpectedness 

dsl %>% 
  ggplot(aes(x = mean_harm, y = mean_unex, col = type)) + 
  geom_point() + 
  geom_text_repel(aes(label = scenario), show.legend = F) + 
  theme(legend.position = "bottom") + 
  guides(text = F) + 
  labs(x = "Harmfulness", 
       y = "Unexpectedness", 
       title = "Average Unexpectedness by Average Harmfulness",
       subtitle = "Liberal Sub-sample")

```

Here we notice a similar relationship to the one above. 

```{r}

# Plot harmfulness by immorality

dsl %>% 
  ggplot(aes(x = mean_imm, y = mean_harm, col = type)) + 
  geom_point() + 
  geom_text_repel(aes(label = scenario), show.legend = F) + 
  theme(legend.position = "bottom") + 
  guides(text = F) + 
  labs(x = "Immorality", 
       y = "Harmfulness", 
       title = "Average Harmfulness by Average Immorality",
       subtitle = "Liberal Sub-sample")
```

The relationship forms almost a 45 degree line. This is incredibly strong; I bet Kurt would be delighted to see this. 

To close this visualization section, I am going to look at how deflection relates to our three measures. 

```{r}

# Unexpectedness by deflection 

dsl %>% 
  ggplot(aes(x = def, y = mean_unex, col = type)) + 
  geom_point() +
  geom_text_repel(aes(label = scenario), show.legend = F) + 
  theme(legend.position = "bottom") + 
  guides(text = F) + 
  labs(x = "Deflection", 
       y = "Unexpectedness", 
       title = "Average Unexpectedness by Deflection",
       subtitle = "Liberal Sub-sample")


# Immorality by deflection 

dsl %>% 
  ggplot(aes(x = def, y = mean_imm, col = type)) + 
  geom_point() + 
  geom_text_repel(aes(label = scenario), show.legend = F) + 
  theme(legend.position = "bottom") + 
  guides(text = F) + 
  labs(x = "Deflection", 
       y = "Immorality", 
       title = "Average Immorality by Deflection",
       subtitle = "Liberal Sub-sample")

# Harmfulness by deflection 

dsl %>% 
  ggplot(aes(x = def, y = mean_harm, col = type)) + 
  geom_point() + 
  geom_text_repel(aes(label = scenario), show.legend = F) + 
  theme(legend.position = "bottom") + 
  guides(text = F) + 
  labs(x = "Deflection", 
       y = "Harmfulness", 
       title = "Average Harmfulness by Deflection",
       subtitle = "Liberal Sub-sample")

```

To an extent, our data show the results that are similar to what we expected. Deflection seems adequate to predict the values of events that obviously involve harm, but it really misses the mark when it comes trangressions that invole breaches of "purity". However, overall, I am surprised by how weak the relationship between deflection and unexpectedness is. 


## First Analysis 

I am going to try to fit a multi-level model to see what best predicts immorality. For this initial exploratory model, I will be using brms with flat priors. I will let the intercepts for participants and scenarios vary, but here I won't explore more co-variances. 

I am going to scale all the variables first. 

```{r}

# Scale variables 

d_long <- 
  d_long %>% 
  mutate(harm_z = as.numeric(scale(harm)) ,
         immoral_z = as.numeric(scale(immoral)) ,
         unexpected_z = as.numeric(scale(unexpected)), 
         deflection_z = as.numeric(scale(def)), 
         scenario = as.factor(scenario))
```

Now let's fit the model

```{r message=FALSE, warning=FALSE}

mod <- brm(data = d_long, 
           formula = immoral_z ~ 1 + harm_z + unexpected_z + deflection_z + (1 | scenario) + (1 | id), 
           family = gaussian, 
           iter = 6000, 
           warmup = 1000, 
           cores = 4, 
           chains = 4)

summary(mod)
```

As we saw, harm and unexpectedness are good predictors of immorality but deflection does not seem to add more information. This is, of course, a very preliminary model. 

I am going to try to run one last exploratory model to see how well deflection predicts unexpectedness, when we take into account IDs and the type of scenario. Again, intercepts are allowed to vary for participants and for each scenario. 

```{r message=FALSE, warning=FALSE}

mod2 <- brm(data = d_long, 
           formula = unexpected_z ~ 1 + deflection_z + (1 | id) + (1 | scenario), 
           family = gaussian, 
           iter = 6000, 
           warmup = 1000, 
           cores = 4, 
           chains = 4)

summary(mod2)
```

The data we have collected so far suggests that deflection is not very informative for predicting unexpectedness. Nonetheless, we need to explore more precise model specifications when the whole sample is available. 