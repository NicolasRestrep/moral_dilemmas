---
title: "The Meanings of Moral Wrongs"
author: "Nicolas Restrepo"
header-includes:
- \usepackage{setspace}
- \doublespacing
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, fig.align='center')
```

```{r packages}
# Packages 
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggrepel)
library(gridExtra)
library(haven)
library(lavaan)
library(lme4)
library(nlme)
library(stargazer)
library(broom)
library(psych)
library(brms)
library(plotly)
library(sjPlot)
library(plot3D)
library(scatterplot3d)
theme_set(theme_light())

# Load in the conservative data
c_data <- read_csv("data/conservatives_full.csv")

#Get rid of the first 2 rows 

c_data <- c_data[-(1:2), ]

# Load pretest data 

p_data <- read_csv("data/pretest.csv")

p_data <- p_data[-(1:3), ]

# Load the liberal data 

l_data <- read_csv("data/liberals_complete.csv")

l_data <- l_data[-(1:2),]

# Now bind them together 

data <- rbind(c_data, p_data, l_data)

# Get attention checks for the data 

data <- data %>% 
  mutate(passed_1 = ifelse(ach_1_1 == "extremely harmful", 1, 0), 
         passed_2 = ifelse(ach_2_1 == "not at all immoral", 1, 0), 
         passed_3 = ifelse(ach_3_1 == "moderately unexpected", 1, 0), 
         passed_4 = ifelse(ach_4_1 == "not at all harmful", 1, 0), 
         passed_5 = ifelse(ach_5_1 == "extremely immoral", 1, 0), 
         passed_6 = ifelse(ach_6_1 == "extremely unexpected", 1, 0), 
         sum_pass = passed_1 + passed_2 + passed_3 + passed_4 + passed_5 + passed_6)

# Now drop cases which did not pass the attention checks 

data <- data %>% 
  filter(sum_pass == 6)

# Create variable that indicates if someone is conservative

data <- data %>% 
  mutate(conservative = ifelse(ideology_1 == 5 | ideology_1 == 6 | ideology_1 == 7, 1, 0)) 


# Mutate all main questions so that we get numbers 

data <- data %>% 
  mutate_at(vars(contains("_h_1")), funs(recode(., 
                                   "not at all harmful" = 1, 
                                   "slightly harmful" = 2, 
                                   "moderately harmful" = 3, 
                                   "very harmful" = 4, 
                                   "extremely harmful" = 5))) %>% 
  mutate_at(vars(contains("_i_1")), funs(recode(., 
                                   "not at all immoral" = 1, 
                                   "slightly immoral" = 2, 
                                   "moderately immoral" = 3, 
                                   "very immoral" = 4, 
                                   "extremely immoral" = 5))) %>% 
  mutate_at(vars(contains("_u_1")), funs(recode(., 
                                   "not at all unexpected" = 1, 
                                   "slightly unexpected" = 2, 
                                   "moderately unexpected" = 3, 
                                   "very unexpected" = 4, 
                                   "extremely unexpected" = 5)))


# Get of of the first set of uninformative columns 

d <- data %>% 
  select(-contains("ach")) %>% 
  select(pkp_h_1:msas_u_1, ideology_1, conservative)

# Now let's create a more amenable dataset 

d <- d %>% 
  mutate(id = 1:n()) %>% 
  select(id, everything()) 

# Rename all variables 

d <- d %>%  
  rename_all(
    funs(str_remove(., "_1"))
    ) %>% 
  mutate_if(is.character, as.numeric)


# Reshape harmful perceptions from wide to long 

d_harm_long <- d %>% 
  select(id, ideology, conservative, contains("_h")) %>% 
  gather(key = "scenario", value = "harm", 4:28) %>% 
  mutate(scenario = str_remove(scenario, "_h$"))

# Reshape immoral perceptions from wide to long 

d_imm_long <- d %>% 
  select(id, ideology, conservative, contains("_i")) %>% 
  gather(key = "scenario", value = "immoral", 4:28) %>% 
  mutate(scenario = str_remove(scenario, "_i$"))

# Reshape unexpected perceptions from wide to long 

d_un_long <- d %>% 
select(id, ideology, conservative, contains("_u")) %>% 
  gather(key = "scenario", value = "unexpected", 4:28) %>% 
  mutate(scenario = str_remove(scenario, "_u$"))

# Now join them 

d_long <- d_harm_long %>% 
  mutate(immoral = d_imm_long$immoral, 
         unexpected = d_un_long$unexpected)

# Load dataset with the deflections 

selected_events <- read_csv("data/full_events.csv")

# Create column for abreviations 

events <- c("pch", 
            "pkp", 
            "tmdp", 
            "adr", 
            "elb", 
            "acr", 
            "jbd", 
            "scc", 
            "ddf", 
            "git", 
            "idb", 
            "ayc", 
            "sip", 
            "ecc", 
            "ccr", 
            "mbr", 
            "msn", 
            "mbw", 
            "php", 
            "mmc", 
            "mmls", 
            "msas", 
            "mpsa", 
            "whh", 
            "thls")

# Create new column 

events_def <- selected_events %>% 
  mutate(scenario = events) %>% 
  select(scenario, def, type, 5:33)

# Add to long dataset 

d_long <- d_long %>% 
  left_join(events_def, by = "scenario")

# Create a variable for negative behavior 

d_long <- d_long %>% 
  mutate(neg_beh = ifelse(be < 0, 1, 0))


# create a summary table for the values of each question 

gd <- d %>% 
  select(-c(id, ideology, conservative)) %>% 
  gather(key = "scenario", 
         value = "score") %>% 
  group_by(scenario) %>% 
  summarise_all(funs(med = median(.), avg = mean(.), maximum = max(.), minimum = min(.), st_dv = sd(.), fq = quantile(., 0.25), tq = quantile(., 0.75))) 

gd <- gd %>% 
  mutate(scenario = str_replace(scenario, "acr", "athlete_cheats_rival"), 
         scenario = str_replace(scenario, "adr", "athlete_deceives_referee"), 
         scenario = str_replace(scenario, "ayc", "athlete_yells_at_coach"), 
         scenario = str_replace(scenario, "ccr", "coach_cheers_rival"), 
         scenario = str_replace(scenario, "ddf", "daughter_disobeys_father"),
         scenario = str_replace(scenario, "ecc", "employee_conspires_with_comp."),
         scenario = str_replace(scenario, "elb", "employee_lies_to_boss"), 
         scenario = str_replace(scenario, "git", "girl_interrupts_teacher"),
         scenario = str_replace(scenario, "idb", "intern_disobeys_boss"), 
         scenario = str_replace(scenario, "jbd", "judge_befriends_defendant"), 
         scenario = str_replace(scenario, "mbr", "man_betrays_relative"), 
         scenario = str_replace(scenario, "mbw", "man_betrays_wife"), 
         scenario = str_replace(scenario, "mmc", "man_marries_cousin"),
         scenario = str_replace(scenario, "mmls", "man_makes_love_sister"), 
         scenario = str_replace(scenario, "mpsa", "married_has_sex_adulterer"), 
         scenario = str_replace(scenario, "msas", "mother_sexually_arouses_son"), 
         scenario = str_replace(scenario, "msn", "mayor_slanders_neighbor"), 
         scenario = str_replace(scenario, "pch", "person_hurts_child"), 
         scenario = str_replace(scenario, "php", "person_hires_prostitute"), 
         scenario = str_replace(scenario, "pkp", "person_kills_person"),
         scenario = str_replace(scenario, "scc", "student_cheats_classmate"), 
         scenario = str_replace(scenario, "sip", "student_insults_professor"), 
         scenario = str_replace(scenario, "thls", "teacher_hits_lazy_student"), 
         scenario = str_replace(scenario, "whh", "wife_hits_husband"), 
         scenario = str_replace(scenario, "tmdp", "teenager_mocks_disabled"))

```
## Introduction

Individuals and groups must constantly classify and categorize moral transgressions; they produce legal and moral codes that group certain types of violations together and, more importantly, that sort these categories according to their perceived severity. There is widespread debate regarding the processes that underpin the categorization of moral wrongdoing. Currently, the most plausible account contends that we attribute moral wrongdoing through prototypical association. In other words, we compare violations to a mental template of what a typical trangression looks like, and immorality is ascribed to the extent that the perceived act resembles that template. Here, I contend that by looking at the connotative meanings associated with different moral vignettes, we can get a clearer idea of what this prototypical moral transgression looks like. Having established the features that identify exemplary moral trangressions, we can calculate how closely certain events resemble these prototypical violations. This gives us a rare opportunity: it allows us to rigurously test whether proximity to a mental exemplar mediates the attribution of immorality. 

## Background

### Attribution of Immorality

Research around moral decision-making has changed throughout the last few decades, shifting emphasis from issues of logical reasoning to questions about deep-seated cognitive processes. The discussion about how people decide what is right and what is wrong had mostly focused on the rational calculations that actors face when presented with a conundrum. The trolley problem has become the main example of this type of research. At heart, this work deals with whether people make moral decisions based on non-negotiable ethical principles or whether they focus on the consequences of their actions. Recently, however, researchers have pointed out that the bulk of our moral decision-making does not look like a trolley problem at all. In fact, those dilemmas are so interesting precisely because how dissimilar they are to our everyday experiences. When we encounter a potentially immoral event, we tend to intuitively know what is and is not permissible. We attribute immorality, not through chains of logical reasoning, but rather through automatic gut feelings; some events just appear morally dubious even if we are not quite capable of articulating why. Research on moral attribution, then, has moved to analyzing the underlying cognitive processes that permit these automatic gut reactions; scholars have started to explore the cognitive mechanisms that make us such swift arbiters of right and wrong. From this line work, two theories have arisen as the main contenders: one posits that moral wrongs belong to different categories and that humans are adept at picking up these differences; the other puts forward a more unified conception of moral cognition. 

The most prominent theory that advances a view of morality as consisting of differentiated domains is known as moral foundations theory (henceforth MFT). This framework emerges as a response to an empirical puzzle: the fact that there are events that we find impermissible, but which do not involve harm or injustice. A typical example is that of two siblings having consensual sex with no consequences. Although no entity is being harmed or wronged, most people still view this scenario as immoral. To explain this gap, MFT scholars argue that the attribution of immorality responds to different underlying logics. In other words, murder and incest are both moral transgressions but they are fundamentally different types of misdeeds and, thus, we assess their wrongness based on different criteria. While the former is judged on the basis of harm, the latter is understood through the lens of what MFT scholars call “purity”. These two codes – along with concerns for care, loyalty, and authority – make up the foundations upon which morality is constructed. MFT, then, puts forward a pluralist vision of moral decision-making, which seeks to explain the empirical breadth and diversity of moral prohibitions. 

There is an underlying argument here about how moral cognition operates. MFT presumes that discrete categorization is the main process through which individuals attribute immorality. Each foundation has certain stimuli and emotions related to it. We have mental faculties that are adept at identifying those stimuli and associating them with the right category. Once we know what “foundation” is being violated, we can produce appropriate moral judgements. For example, when we see an athlete cheating, we identify the event as a fairness violation and feel outraged. When confronted with incest, we correctly categorize it as a purity violation and tend to experience disgust. The bottom line is that, according to this theory, attributing immorality entails correctly identifying what set of moral logics an event appears to breach and then reacting appropriately. 

This position has been recently criticized by scholars who are pushing for a more integrated conception of morality. Recent empirical evidence shows that the five moral foundations are all highly correlated. Different moral prohibitions, then, seem to be cut from the same cloth, and cannot be neatly parceled out into distinct groups. According to Gray and Schein, the unifying dimension that underpins moral decision-making is harm. We judge actions to be immoral insofar as we can perceive them as harmful. Interestingly, the language of harm even creeps into our understanding of moral breaches that do not seem to directly affect any entities. Thus, incestual marriages are often described as harming the health – the gene pool - of the group and breaching religious dietary taboos is often depicted as harming one’s soul or that of the ancestors. The argument of harm being the central engine for moral decision-making is certainly not new, but it has accrued significant empirical validation in the last decade. The evidence suggests that perceptions of harm shape how we determine immorality and how we assess severity. Rather than being organized around different logics, then, morality seems to be underpinned primarily by perceptions of harmfulness.

This position, in turn, implies a more continuous vision of moral cognition. Transgressions share an underlying structure: they involve a cognizant agent directing a harmful behavior towards a vulnerable patient. This framework represents a cognitive template against which we compare events to gauge how immoral they are. Situations that closely resemble this template are quickly flagged as immoral. The farther away an event is from this prototypical structure, however, the harder it will be for us to understand it as immoral. This explanation relies heavily on the idea that category membership is ascribed, not through a set of exclusionary criteria, but rather due to proximity to a salient exemplar. Moral cognition, then, does not entail sorting an event into discrete categories to assess what kind of moral code it breaches. Instead, it entails placing a situation on a continuum, more or less distant from our mental template of a moral wrong. There is empirical evidence that supports this argument: individuals tend to label actions as immoral more quickly if they also think they are harmful. Thus, the most cognitively plausible account of the attribution of immorality suggests that we classify moral violations based on their proximity to a fuzzy mental template – one that depicts an intentional agent causing harm to a vulnerable victim.

Though convincing, this account still leaves crucial questions unanswered. Although proponents argue persuasively for the existence of a cognitive template of moral wrongdoing, the characteristics of this exemplar remain opaque. For instance, it is unclear what makes an action seem prototypically harmful or a victim obviously vulnerable. Thus, we do not know what the prototypical moral transgression looks like, let alone how to go about calculating whether actions are distant from it. Relatedly, it is key to further specify exactly what role distance from the prototype plays in the attribution of immorality. We know that proximity to the template is not necessarily related to the severity of transgressions; there are violations – such as incest – that, while distant from the prototypical moral dyad, are considered very harmful.  Therefore, distance from the prototype should not necessarily be related to perceived severity. What this distance should predict, then, is the cognitive difficulty that it takes individuals to reach their assessment. In other words, proximity to the exemplary moral wrong should not necessarily reflect how severe we think actions are but rather how easily we can categorize them as immoral. In this paper, I aim to address these two gaps. Drawing from sociological work, I seek to clarify what a prototypical moral transgression looks like and to show that distance from it affects how easily individuals can categorize events as immoral. 

### The Social Meanings of Moral Transgressions

A good first step towards providing a clearer description of what a prototypical moral wrong might look like is to recognize that mental templates are eminently social. The cultural landscapes in which we are embedded shape how we envision categories, and the exemplars around which they are organized. In other words, our readiness to say who counts as African American (Monk, 2014) or as poor (Valentino and Hunzaker, 2019) changes depending on the social positions in which we are situated. This is a crucial point for this analysis: it means that we can examine the cultural meanings that are associated with different transgressions to begin to piece together an outline of a prototypical moral wrong. The central challenge is to be able is to map a rigorous measure of cultural meaning onto moral transgressions. Luckily, there are sociological traditions that have collected large repositories of semantic structures that we can use to accomplish this. In this analysis, I will be using the dictionaries of affective meanings collected by Affect Control Theory (henceforth ACT) scholars. 

Drawing from its symbolic interactionist roots, ACT starts from the premise that individuals attach affective meanings to social concepts and that those semantic structures can be reduced to a set of measurable dimensions. Building on Osgood et al.’s (1957) work, it contends that there are three basic dimensions of meaning: evaluation, potency, and activity. Evaluation pertains to characteristics such as goodness and badness. Potency, in turn, captures notions of power and weakness, while Activity relates to issues of liveliness and quietness. Osgood et al.’s (1975) extensive research demonstrates the cross-cultural validity of these dimensions of affective meaning, and their utility has been broadly recognized.

Using these dimensions, it is possible to collect rigorous measures of the affective meanings that individuals attach to particular concepts. The measuring technique used is called semantic differentials: respondents are asked to rate a series of concepts on a scale ranging from, for example, very weak to very strong. The averages of all three dimensions then are computed (Heise, 1979) and each concept is assigned an EPA profile. This means that it is possible to place identities and behaviors in a three-dimensional space and to compare their underlying semantic structures; babies, for instance, are described as very good, very weak, and somewhat lively, while murderers are depicted as very bad, very powerful, and slightly active. Importantly, these values have proved to be both remarkably accurate and generalizable. Here, then, we have a framework that makes meaning measurable and formalizable. By locating social concepts in a three-dimensional semantic space, we can shed light on the symbolic structures through which cultures organize the social world.

We can leverage these large repositories of affective meanings to explore the underlying semantic structures of moral transgressions. Research about moral cognition has primarily used fictional scenarios to examine how respondents assess immorality. These fictional scenarios tend to share a grammatical structure (actor-behavior-object) which is, incidentally, the main unit of analysis of ACT. This means that we can take advantage of their dictionaries of affective meanings to translate moral scenarios into a format that allows us to examine their underlying semantic structure. For example, a commonly used fictional scenario is: 

> You see a teacher hitting a student’s hand with a ruler for falling asleep in class.

Ascribing EPA values to each component of the sentence, we can produce the following translation: 

> Teacher [2.5; 2.31; 0.32] hits [-2.66; 1.30; 2.12] lazy student [-0.42; -0.76; -1.56]

These formal translations, in turn, help us explore moral transgressions more systematically. Specifically, we can examine the shared and recurrent semantic features of moral violations. In other words, we can analyze the affective meanings associated with prototypically harmful acts such as “murder” or with characteristically vulnerable patients such as “children”. Furthermore, we can measure the differences and overlaps between the semantic structures of transgressions, examining what makes violations more or less prototypical. As a result, we would be able to quantify deviations from prototypicality, which would allow us to shed light on whether this distance is indeed informative for understanding the attribution of immorality. This is precisely what the following two studies seek to accomplish. 

## Study 1 

In the first study, I aim to validate whether respondents interpret the translated scenarios consistently and to examine what are the semantic features that have the biggest impact in their opinions about the immorality violations. For this, I translated 25 of the most common vignettes in this literature into the EPA semantic space. Using the Prolific platform, I asked participants (n = 205) about the extent to which they considered each scenario harmful, immoral, and unexpected. After filtering for missed attention checks, there is a total of 194 usable responses. Figure 1 shows the relationship between the average immorality of each scenario and its average harmfulness and unexpectedness. The results resonate with previous empirical evidence: immorality is positively related to both harmfulness and unexpectedness. The first result further reaffirms the relationship between harm and immorality. The latter, in turn, lends credence to the notion that severe transgressions tend to be perceived as more unexpected because they entail the breaching of social norms. For the purposes of the study, the most important point is that the translated scenarios are being interpreted consistently; this means that there was not a significant loss of information when the vignettes were translated into the new format. 

```{r}

# create mean measures from the long dataset

dsl <- d_long %>% 
  group_by(scenario, type, def, dop) %>% 
  summarise(mean_harm = mean(harm), 
            mean_imm = mean(immoral), 
            mean_unex = mean(unexpected)) 


# Recreate Gray and Keeney's plot

 p1 <- dsl %>% 
  ggplot(aes(x = mean_imm, y = mean_harm)) + 
  geom_point(aes(pch = type)) + 
  theme() + 
  guides(text = F) + 
  labs(x = "Immorality", 
       y = "Harmfulness")

# Harm by unexpectedness plot 

 p2 <- dsl %>% 
  ggplot(aes(x = mean_harm, y = mean_unex)) + 
  geom_point(aes(pch = type)) + 
  theme() +
  guides(text = F) + 
  labs(x = "Harmfulness", 
       y = "Unexpectedness")
 
 grid.arrange(p1, p2, ncol = 1, top = "Figure 1")
```
In order to examine how the underlying semantic structures of violations affect perceptions of immorality, I conduct statistical analyses with immorality ratings as the dependent variable and the EPA values of each component as the main independent variables. Here, I build cross-classified models, giving each respondent and each scenario its own intercept. In order to select the most appropriate model for the current analysis, I use different measures of information criteria. Across the board, the most informative model for the current data seems to be a cross-classified model that includes the EPA values but that foregoes additional covariates, such as gender and political ideology. Figure 2 shows the coefficient plots for two models; the second one excludes the so-called ‘purity’ scenarios from the analysis. Both models show that there are three semantic features that seem particularly informative when trying to understand the attribution of immorality: the behavior’s evaluation, the behavior’s potency, and the object’s potency. These results resonate with the theory of dyadic morality. Negative and potent behaviors are perceived as more immoral. In turn, as the object’s potency increases, the immorality of the act tends to decrease. This finding speaks directly theory’s idea of vulnerability. As actors appear less potent, the behaviors directed at them are considered more immoral. This adds plausibility to the notion that the vulnerability of the victim is key when assessing immorality.

```{r}
# Scale all variables before the analysis
d_long_scaled <- 
  d_long %>% 
  mutate_at(c("id", "type", "scenario", "conservative", "neg_beh"), ~as.factor(.)) %>% 
  mutate_if(is.numeric, scale)

m1 <- lmer(immoral ~ 1 + ae + ap + aa + be + bp + ba + oe + op + oa + (1 | id) + (1 | scenario),
           data = d_long_scaled)

m2 <- lmer(immoral ~ 1 + ae + ap + aa + be + bp + ba + oe + op + oa + (1 | id) + (1 | scenario),
           data = filter(d_long_scaled, type != "purity"))

p3 <- plot_model(m1, sort.est = T, title = "Including all scenarios") 
p4 <- plot_model(m2, sort.est = T, title = "Exluding purity")

grid.arrange(p3,p4, top = "Figure 2", ncol = 2)
```
Though informative, the coefficients in the first model do not reach conventional levels of significance. However, in the model that excludes the ‘purity’ transgressions, the coefficients for the object’s potency and the behavior evaluation become significant. This shows that there might be something about the excluded violations that does not quite fit with the semantic patterns evidenced in the rest of the scenarios. When we plot the scenarios in three-dimensional space, this difference becomes evident. In Figure 3, the axes are the three semantic features we identify as particularly important. We notice that the so-called ‘purity’ transgressions are grouped away from most of the other scenarios. They do not seem to share the same underlying semantic structure as other scenarios, but they are amongst those rated as most immoral and most harmful. We need to think, then, about what distance in this semantic space means. Study 2 seeks to answer this question. 

```{r}
events_def <- events_def %>% 
  mutate(type_num = case_when(type == "harm" ~ 1, 
                              type == "purity" ~ 2, 
                              type == "fairness" ~ 3, 
                              type == "authority" ~ 4, 
                              type == "loyalty" ~ 5)) %>% 
  mutate(type_num = as.factor(type_num))
levels(events_def$type_num) <- c("harm", "purity", "fairness", "authority", "loyalty")
shapes <-  c(5:9) 
shapes <- shapes[as.numeric(events_def$type_num)]

s3d <- scatterplot3d(events_def[, c(7,8,11)], pch = shapes, main = "Figure 3")
legend(s3d$xyz.convert(2.5, 0.5, 1), legend = levels(events_def$type_num),
      pch = c(5:9))
```

## Study 2

In this study, I ask respondents (n = 92) to tell me whether they categorize the 25 scenarios as immoral or not immoral, harmful or harmless. In each question, the scenario appears in the middle of the screen and the dichotomous categories are shown at the bottom, on opposite sides of the page. Using their keyboards, the participants indicate the category to which the event belongs. The variable of interest, here, is how long it takes individuals to categorize the violations. By using this method, I root this analysis in a longstanding tradition of studies that have implemented reaction time data to explore issues surrounding social cognition. 

This analysis seeks to test whether the attribution of immorality does occur through the association of the situation at hand with a prototypical mental template. As discussed above, this theory does not necessarily predict that proximity to the exemplar necessarily leads to higher levels of perceived immorality. Our data confirm this: while violations involving sexual taboos are quite distinct from the rest of the transgressions, some of them rank amongst the most severe. Thus, distance form a prototypical transgression should not predict severity. If the theory is correct, however, it should predict how cognitively difficult it is to attribute immorality. The further away an event is from our mental template, the harder it should be for us to understand it as immoral. This is the idea I aim to test in this study. I aim to analyze whether distance from a prototypical moral wrong predicts how long it takes respondents to categorize a scenario as immoral. 

To undertake this analysis, I need to choose which one of the translated scenarios to use as the exemplary transgression. The data from the previous analysis helps inform this decision: a prototypical moral violation should involve a potent and bad behavior directed towards a weak victim. From the available vignettes, the one that best reflects this semantic structure is: "a person hurts a child". This scenario will be used as the prototype – the reference point against which semantic distance will be calculated. Distance from the prototypical transgression will be defined as Euclidean distance in the three-dimensional space presented in Figure 3. If the prototypical moral transgression is $p$, then distance for scenario $i$ will be defines as: 

$$ D_p = \sqrt{(BP_p - BP_i)^2 + (BE_p - BE_i)^2 + (OP_p - OP_i)^2} $$
Figure 4 shows the relationship between distance from the prototype and reaction time. We notice a slight positive relationship, which resonates with the theory that is being tested. Note, however, that reaction time seems to be highly correlated with the length of the vignette. Scenarios like “a married person has sex with an adulterer” and “an employee conspires with a competitor” have the highest reaction times. Reaction type data is quite sensitive to the length of the prompts that respondents have to categorize and, therefore, in the analyses I need to make sure I account for this factor. 

```{r, message = FALSE}
# Load in the data 
rt_liberal <- read_csv("rt_liberal.csv")

# Delete unnecessary rows
rt_liberal <- rt_liberal[-(1:2),]

# How many people passed the attention checks?
rt_liberal <- rt_liberal %>% 
  mutate(passed = if_else(att_1 == "Harmless (K)" & att_2 == "Immoral (J)" & att_3 == "Harmful (J)", 1, 0)) 

# Filter out the people who failed the attention checks 
rt_liberal <- rt_liberal %>% 
  filter(passed == 1)

# Only keep reaction time data and put it in the long format 
rt_liberal_times <- rt_liberal %>% 
  select(ends_with("Page Submit")) %>% 
  mutate(ids = 1:92) %>% 
  pivot_longer(1:50, names_to = "scenario", values_to = "reaction_time") %>% 
  mutate(scenario = str_remove(scenario, "_t_Page Submit$"))

# Get summary statistics 
gd <- rt_liberal_times %>% 
  mutate(reaction_time = as.numeric(reaction_time)) %>% 
  group_by(scenario) %>% 
  summarise(avg = mean(reaction_time), 
            st_dv = sd(reaction_time),
            med = median(reaction_time)) %>% 
  mutate(ci_lower = avg - 1.96*st_dv, 
         ci_upper = avg + 1.96*st_dv)

# Replace them with the appropriate median
rt_liberal_times[767,] <- gd[gd$scenario=="i_ccr",4]
rt_liberal_times[1119,] <- gd[gd$scenario=="i_msn",4]
rt_liberal_times[1514,] <- gd[gd$scenario=="i_ayc",4]
rt_liberal_times[2757,] <- gd[gd$scenario=="i_elb",4]

# Now let's plot harm 

# Keep only harm questions 

gdh <- gd[str_which(gd$scenario, "h_"),]


# Get only Immorality questions 
gdi <- gd[str_which(gd$scenario, "i_"),]

# Create a manageable wide dataframe 

rtw <- rt_liberal %>% 
  select(ends_with("Page Submit")) %>% 
  mutate(ids = 1:92) 

# Create a long dataframe for harm 

d_long_harm <- rtw %>% 
  select(ids, starts_with("h_")) %>% 
  pivot_longer(2:26, names_to = "scenario", values_to = "reaction_time_harm") %>% 
  mutate(scenario = str_remove(scenario, "_t_Page Submit$")) %>% 
  mutate(scenario = str_remove(scenario, "^h_"))

# Create a long dataframe for immorality 

d_long_imm <- rtw %>% 
  select(ids, starts_with("i_")) %>% 
  pivot_longer(2:26, names_to = "scenario", values_to = "reaction_time_imm") %>% 
  mutate(scenario = str_remove(scenario, "_t_Page Submit$")) %>% 
  mutate(scenario = str_remove(scenario, "^i_"))

# Now join them 

d_long <- d_long_harm %>% 
  mutate(reaction_time_imm = d_long_imm$reaction_time_imm) %>% 
  mutate(reaction_time_harm = as.numeric(reaction_time_harm), 
         reaction_time_imm = as.numeric(reaction_time_imm))

# Let's get some information about the events in there 

# Load dataset with the deflections 

selected_events <- read_csv("data/full_events.csv")

# Create column for abreviations 

events <- c("phc", 
            "pkp", 
            "tmdp", 
            "adr", 
            "elb", 
            "acr", 
            "jbd", 
            "scc", 
            "ddf", 
            "git", 
            "idb", 
            "ayc", 
            "sip", 
            "ecc", 
            "ccr", 
            "mbr", 
            "msn", 
            "mbw", 
            "php", 
            "mmc", 
            "mmls", 
            "msas", 
            "mpsa", 
            "whh", 
            "thls")

# Create new column 

events_def <- selected_events %>% 
  mutate(scenario = events) %>% 
  select(scenario, def, type, 5:33)

# Add to long dataset 

d_long <- d_long %>% 
  left_join(events_def, by = "scenario")

# Get the averages so we can plot them 

dsl <- d_long %>% 
  group_by(scenario, type) %>% 
  summarise(mean_harm = mean(reaction_time_harm), 
            mean_imm = mean(reaction_time_imm)) %>% 
  ungroup()


# Name the scenarios with the full length 

dsl <- dsl %>% 
  mutate(full_string = case_when(scenario == "acr" ~ "an_athlete_cheats_their_rival", 
                                 scenario == "adr" ~ "an_athlete_deceives_the_referee", 
                                 scenario == "ayc" ~ "an_athlete_yells_at_their_coach", 
                                 scenario == "ccr" ~ "a_coach_cheers_for_the_rival", 
                                 scenario == "ddf" ~ "a_daughter_disobeys_her_father", 
                                 scenario == "ecc" ~ "an_employee_conspires_with_a_competitor", 
                                 scenario == "elb" ~ "an_employee_lies_to_the_boss", 
                                 scenario == "git" ~ "a_girl_interrupts_her_teacher", 
                                 scenario == "idb" ~ "an_intern_disobeys_their_boss", 
                                 scenario == "jbd" ~ "a_judge_befriends_the_defendant", 
                                 scenario == "mbr" ~ "a_man_betrays_his_relative", 
                                 scenario == "mbw" ~ "a_man_betrays_his_wife", 
                                 scenario == "mmc" ~ "a_man_marries_his_cousin", 
                                 scenario == "mmls" ~ "a_man_makes_love_to_his_sister", 
                                 scenario == "mpsa" ~ "a_married_man_has_sex_with_an_adulterer", 
                                 scenario == "msas" ~ "a_mother_sexually_arouses_her_son", 
                                 scenario == "msn" ~ "a_mayor_slanders_a_neighbor", 
                                 scenario == "phc" ~ "a_person_hurts_a_child", 
                                 scenario == "php" ~ "a_person_hires_a_prostitute", 
                                 scenario == "pkp" ~ "a_person_kills_a_person", 
                                 scenario == "scc" ~ "a_student_cheats_their_classmate", 
                                 scenario == "sip" ~ "a_student_insults_the_professor", 
                                 scenario == "thls" ~ "a_teacher_hits_a_lazy_student", 
                                 scenario == "whh" ~ "a_wife_hits_her_forgetful_husband", 
                                 scenario == "tmdp" ~ "a_teenager_mocks_a_disabled_person"))

# Add the short versions again for the plot

dsl <- dsl %>% 
  mutate(length = str_count(full_string))


# Create function to calculate the euclidean distance in three-dimensional space 

events_values <- events_def %>% 
  select(scenario, op, be, bp)

eucl_dist_pkp <- function(x) { 
    op <-  events_values[x, 2] 
    be <-  events_values[x, 3] 
    bp <-  events_values[x, 4]
  
   # Formula   
  # The values of the prototype are always the ones the events are compared against
  distance <- sqrt((0.95 - op)^2 + ((-4.26) - be)^2 + (1.95 - bp)^2)
   return(as.double(distance))
}


distances_pkp <- map_dbl(1:25, eucl_dist_pkp)

events_values_pkp <- events_values %>% 
  cbind(distances_pkp) %>% 
  select(scenario, distances_pkp)

# Join values with the long dataset 

dsl <- dsl %>% 
  left_join(events_values_pkp, by = "scenario")

# Create new function with Person hurts child as the prototype 

eucl_dist_phc <- function(x) { 
    op <-  events_values[x, 2] 
    be <-  events_values[x, 3] 
    bp <-  events_values[x, 4]
  
   # Formula   
  # The values of the prototype are always the ones the events are compared against
  distance <- sqrt(((-1.14) - op)^2 + ((-3.17) - be)^2 + (1.06 - bp)^2)
   return(as.double(distance))
}


distances_phc <- map_dbl(1:25, eucl_dist_phc)

events_values_phc <- events_values %>% 
  cbind(distances_phc) %>% 
  select(scenario, distances_phc)

# Join values with the long dataset 

dsl <- dsl %>% 
  left_join(events_values_phc, by = "scenario")

# Plot reaction time for immorality and distances from prototype. 

dsl %>% 
  ggplot(aes(x = distances_phc, y = mean_imm)) + 
  geom_point(aes(pch = type)) +
  labs(x = "Distance from prototype", 
       y = "RT Immorality", 
       subtitle = "Reaction time by distance from the prototype", 
       title = "Figure 4")


```
In the statistical analysis, I will use reaction time as my dependent variable and distance from the prototype as my independent variable. Here, I use a cross-classified model that adds random intercepts for individuals and for scenarios. I also make sure to control for the length of the vignette. Length here is defined as the number of characters in the sentence. Figure 5 shows the coefficients of the model. Under the assumptions of the model, distance from the prototype is positively related with reaction time, even after controlling for length. A one standard deviation increase in the distance from the prototype is predicted to increase reaction time by 0.09 standard deviations. This coefficient, however, does not meet the criteria for conventional significance. However, the confidence interval [from -.01 to 0.19] suggests that the coefficient is likely positive. 
```{r}

# Let's first tidy the data a bit 
# Get the lengths and put them in the main dataset 

lengths <- dsl %>% 
  select(scenario, length, distances_phc, distances_pkp)

d_long <- d_long %>% 
  select(1:16) %>% 
  left_join(lengths, by = "scenario")

# Scale the dataframe 

d_long_scaled <- 
  d_long %>% 
  mutate_at(c("ids", "type", "scenario"), ~as.factor(.)) %>% 
  mutate_if(is.numeric, scale)

m1 <- lmer(reaction_time_imm ~ 1 + distances_phc + length + (1 | ids) + (1 | scenario),
           data = d_long_scaled)

plot_model(m1, sort.est = T, title = "Figure 5", show.values = T, value.offset = .3)
```
## Discussion

The studies above show that there is much to be gained by studying the underlying semantic structures of moral transgressions. Research about moral decision-making has relied heavily on the use of fictional vignettes to elicit perceptions of harmfulness and immorality. Here, I leverage existent repositories of cultural meanings to examine the underlying semantic meanings that are associated with the different components of these scenarios. This technique helps me accomplish two main things: it allows me to bring greater rigor to existent empirical evidence and it lets me test current presuppositions about how moral cognition unfolds. Overall, this research shows that examining the connotative meanings of moral violations can help us shed light on the process through which individuals come to decide what is permissible and what is not. 

At a general level, this analysis presents a novel approach to a well-trodden method in the study of moral cognition. I take advantage of the fact that sociologists have collected large dictionaries of affective means that contain many of the identities and behaviors that feature in the vignettes used by researchers interested in moral decision-making. This coincidence allows me to translate these fictional scenarios into a syntax that formalizes their semantic properties. In other words, this technique allows us me to measure and contrast the cultural meanings associated with moral scenarios. This, in turn, yields insightful findings. Consistent with widely accepted theories of morality, I find that transgressions tend to have a patterned structure: they involve a bad and powerful behavior directed at a vulnerable victim. Previous work highlights the importance of the evaluation of the actor and of the victim, but my findings point out the significance of the patient’s vulnerability. This semantic feature is a theoretical cornerstone of the dyadic theory of morality.  By uncovering this underlying semantic structure, we can place moral transgressions in a cartesian plane and contrast their positions. This technique opens new opportunities related to what we can do with fictional vignettes. It helps us look at the formal properties of scenarios and to examine whether underlying relationships exist at a connotative level. 

The ability to measure distances between transgressions allows me to provide a rigorous test of how moral cognition operates. Currently, the most plausible account of moral cognition presupposes that individuals evaluate situations by comparing them with a cognitive template of a prototypical moral transgression. By analyzing the semantic structures of violations, I can make an informed decision about what constitutes an exemplary violation and calculate distances between the prototype and other scenarios. The results of Study 2 suggest that distance from the prototypical moral violation is indeed positively associated with how long it takes individuals to label an event as immoral. This lends credence to the idea that moral cognition occurs as agents compare an event with a cognitive template of what a typical moral violation looks like. While not definitive, this analysis helps adjudicate one of the central ongoing debates in the study of moral reasoning. It provides rigurous evidence that supports the vision of moral cognition as a continuous process, not underpinned by discrete categories but rather organized around fuzzy cognitive templates. 

Additionally, these studies also inform the debates that have unfolded around the existence of “harmless” wrongs. While the findings reaffirm the idea that moral violations are not underpinned by different logics, they show that the scholarly fascination around “harmless” transgressions might not be entirely unfounded. When the transgressions are placed in a common plane, we notice that the so-called “purity” transgressions – the ones often identified as “harmless” wrongs – are all grouped in one corner, away from the majority of the events. Thus, while these events rank amongst the most immoral, they are distant from our cognitive template of what a moral violation should look like. This seemingly paradoxical tension might explain why these transgressions have been ascribed such distinctiveness. As study 2 shows, this tension can be explained by noting that distance from exemplary violations does not necessarily affect a transgression’s severity but rather how long it takes agents to label it as immoral. This account, in turn, suggest a plausible explanation of why “purity” transgressions tend to be shrouded in taboo and fascination: given that it is more difficult to attribute immorality to these atypical violations, we might have to build a scaffolding of social prohibitions around them to better signal their wrongness. Now, these are only conjectures, but they provide a set of hypotheses and plausible mechanisms that can be tested. A semantic approach to moral cognition, then, might help us make progress in solving one of the central puzzles in this line of research.
